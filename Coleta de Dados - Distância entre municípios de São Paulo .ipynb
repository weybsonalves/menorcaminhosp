{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta de Dados\n",
    "\n",
    "Vamos começar importando as bibliotecas que usaremos para obter os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import pandas as pd\n",
    "import requests\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos acessar a página da Wikipedia dos municípios de São Paulo usando a biblioteca BeautifulSoup4 e extrair o nome e o link da página da Wikipedia de cada cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pt.wikipedia.org/wiki/Lista_de_municípios_de_São_Paulo'\n",
    "page = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios = []\n",
    "links = []\n",
    "for x in soup.find('table', class_='wikitable sortable').find_all(style='text-align:left;'):\n",
    "    municipios.append(x.find_all('a')[-1].get_text())\n",
    "    mun_url = requests.get('https://pt.wikipedia.org' + x.find_all('a')[-1]['href'])\n",
    "    mun_soup = bs4.BeautifulSoup(mun_url.text, 'html.parser')\n",
    "    redirected_url = mun_soup.find('link', rel='canonical')['href']\n",
    "    links.append(redirected_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os links de cada cidade, extrairemos os dados referentes aos municípios de São Paulo que são limítrofes de cada munícipio de São Paulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios_limitrofes = []\n",
    "for i, l in enumerate(links):\n",
    "    municipios_limitrofes.append([])\n",
    "    page_l = requests.get(l)\n",
    "    soup = bs4.BeautifulSoup(page_l.text, \"html.parser\")\n",
    "    soup_td = soup.find('table', class_='infobox_v2').find_all('td')\n",
    "    for j, limit in enumerate(soup_td):\n",
    "        if limit.get_text().replace('\\n', '').strip() == 'Municípios limítrofes':\n",
    "            for mun in soup_td[j+1].find_all('a'):\n",
    "                mun_url = requests.get('https://pt.wikipedia.org' + mun['href'])\n",
    "                mun_soup = bs4.BeautifulSoup(mun_url.text, 'html.parser')\n",
    "                redirected_url = mun_soup.find('link', rel='canonical')['href']\n",
    "                if redirected_url in links:\n",
    "                    municipios_limitrofes[i].append(municipios[links.index(redirected_url)])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se um município x é vizinho de um município y, esse município y também é vizinho do município x. Portanto, vamos checar se não há nenhuma cidade faltando na lista de cidades limítrofes de cada cidade e, caso haja, adicioná-la à lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(municipios_limitrofes):\n",
    "    for j, m in enumerate(municipios_limitrofes):\n",
    "        if municipios[i] in m and municipios[j] not in c:\n",
    "            municipios_limitrofes[i].append(municipios[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos salvar a lista de municípios e seus municípios limítrofes em um arquivo TXT para caso precisemos acessar os dados nvoamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('municipios_sp.txt', 'a') as m:\n",
    "    for mun in municipios:\n",
    "        m.write(mun + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('municipios_sp_limitrofes.txt', 'a') as ml:\n",
    "    for mun_limit in municipios_limitrofes:\n",
    "        ml.write(str(mun_limit) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o acesso das listas, vamos criar um dicionário que mapeia os nomes para os respectivos índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_idx = dict()\n",
    "for i in range(len(municipios)):\n",
    "    name_to_idx[municipios[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos começar a coletar os dados referente às distâncias entre cada município vizinho. Primeiramente, vamos obter a latitude e longitude de cada cidade acesando a API do Nominatim por meio do GeoPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent='was5@cin.ufpe.br')\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=2)\n",
    "lat_long = [list(geocode({'city': municipio, 'state': 'São Paulo', 'country': 'Brasil'}))[-1] for municipio in municipios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também salvaremos esses dados em um arquivo TXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lat_long_municipios_sp.txt', 'a') as ll:\n",
    "    for latlong in lat_long:\n",
    "        ll.write(str(latlong)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos as coordenadas de cada cidade, vamos utilizar a API do Open Street Routing Machine (OSRM) para obter os dados da distância de carro entre as cidades vizinhas. \n",
    "Como faremos uma quantidade razoável de acessos, vamos acessar a API localmente usando o Docker. Para isso, vamos baixar [os dados do OpenStreetMap da região sudeste do Brasil](http://download.geofabrik.de/south-america/brazil/sudeste.html) e proceder conforme consta no [repositório da OSRM](https://github.com/Project-OSRM/osrm-backend).\n",
    "\n",
    "Para informações sobre o funcionamento da API, acesse a [documentação da OSRM](http://project-osrm.org/docs/v5.23.0/api/#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arestas = []\n",
    "estradas = []\n",
    "for i, mun_limits in enumerate(municipios_limitrofes):\n",
    "    for ml in mun_limits:\n",
    "        j = name_to_idx[ml]\n",
    "        if not {i, j} in arestas:\n",
    "            arestas.append({i, j})\n",
    "            distancias = []\n",
    "            for route in requests.get(f'http://localhost:5000/route/v1/car/{lat_long[i][1]},{lat_long[i][0]};{lat_long[j][1]},{lat_long[j][0]}?overview=false&alternatives=3').json()['routes']:\n",
    "                distancias.append(round(route['distance']/1000, 1))\n",
    "            estradas.append([i, j, min(distancias)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos salvar esses dados em um arquivo TXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('distancias_municipios_sp.txt', 'a') as dm:\n",
    "    for e in estradas:\n",
    "        dm.write(f'{e[0]} {e[1]} {e[2]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
